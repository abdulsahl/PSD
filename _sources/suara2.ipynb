{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a57728af",
   "metadata": {},
   "source": [
    "# **Klasfikasi Suara Gabungan (Perintah + Orang)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3099e3",
   "metadata": {},
   "source": [
    "Pengenalan suara adalah teknologi yang memungkinkan komputer atau mesin \n",
    "untuk mengenali, memahami, dan memproses ucapan manusia sehingga dapat \n",
    "diterjemahkan menjadi perintah atau teks. \n",
    "\n",
    "Dalam analisis ini, saya membangun sebuah model yang mampu mengklasifikasikan suara berdasarkan **perintah (`buka`/`tutup`)** dan **siapa yang berbicara (`sahl`/`naufal`)** secara bersamaan. Model ini akan dilatih untuk mengenali empat kelas yang berbeda:\n",
    "- `buka_sahl`\n",
    "- `tutup_sahl`\n",
    "- `buka_naufal`\n",
    "- `tutup_naufal`\n",
    "\n",
    "Dataset yang digunakan berasal dari rekaman suara pribadi. Tujuan akhirnya adalah menghasilkan satu model klasifikasi yang siap untuk digunakan dalam tahap *deployment*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf86965",
   "metadata": {},
   "source": [
    "## **1. Data Understanding & Feature Extraction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e53127",
   "metadata": {},
   "source": [
    "### **1.1 Install & Import Dependency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343dfd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install librosa soundfile numpy matplotlib seaborn scikit-learn pydub ffmpeg-python joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817274d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import joblib\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd039d80",
   "metadata": {},
   "source": [
    "### **1.2 Ekstraksi Fitur dari Data Suara**\n",
    "\n",
    "Pada tahap ini, semua file audio (`.m4a` atau `.wav`) akan diproses untuk mengekstrak fitur-fitur statistik yang relevan. Target klasifikasi (`label`) akan digabungkan menjadi satu, contohnya `buka_sahl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5aa6bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 800\n",
      "Jumlah fitur per file: 876\n",
      "\n",
      "Distribusi Label:\n",
      "label\n",
      "buka_sahl       200\n",
      "tutup_sahl      200\n",
      "buka_naufal     200\n",
      "tutup_naufal    200\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data Head:\n",
      "          0         1         2         3         4          5         6  \\\n",
      "0  0.000012  0.117857 -0.627928  1.000000  1.850656  14.627781  0.036750   \n",
      "1  0.000012  0.117857 -0.627928  1.000000  1.850656  14.627781  0.036750   \n",
      "2 -0.000134  0.146948 -0.617306  1.000000  1.545906   7.272887  0.026841   \n",
      "3 -0.000134  0.146948 -0.617306  1.000000  1.545906   7.272887  0.026841   \n",
      "4 -0.000354  0.255693 -1.000000  0.966238  0.315259   2.364644  0.029914   \n",
      "\n",
      "          7    8         9  ...       867       868       869       870  \\\n",
      "0  0.023301  0.0  0.097656  ...  0.791086 -0.127478 -0.479910 -0.014375   \n",
      "1  0.023301  0.0  0.097656  ...  0.791086 -0.127478 -0.479910 -0.014375   \n",
      "2  0.019015  0.0  0.091797  ...  1.225600 -0.113959  0.036819  0.022988   \n",
      "3  0.019015  0.0  0.091797  ...  1.225600 -0.113959  0.036819  0.022988   \n",
      "4  0.025831  0.0  0.116211  ...  1.864736  0.235991  1.024090  0.023976   \n",
      "\n",
      "        871       872       873       874       875      label  \n",
      "0  0.381730 -1.021210  0.833768  0.061726 -0.526389  buka_sahl  \n",
      "1  0.381730 -1.021210  0.833768  0.061726 -0.526389  buka_sahl  \n",
      "2  0.490507 -1.665088  1.745695 -0.190680  1.422641  buka_sahl  \n",
      "3  0.490507 -1.665088  1.745695 -0.190680  1.422641  buka_sahl  \n",
      "4  0.495029 -1.554793  1.566077 -0.369988  0.456948  buka_sahl  \n",
      "\n",
      "[5 rows x 877 columns]\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"data_suara\"\n",
    "labels = [\"buka_sahl\", \"tutup_sahl\", \"buka_naufal\", \"tutup_naufal\"]\n",
    "\n",
    "features = []\n",
    "full_labels = []\n",
    "\n",
    "def extract_stats(arr):\n",
    "    return [\n",
    "        np.mean(arr),\n",
    "        np.std(arr),\n",
    "        np.min(arr),\n",
    "        np.max(arr),\n",
    "        scipy.stats.skew(arr),\n",
    "        scipy.stats.kurtosis(arr)\n",
    "    ]\n",
    "\n",
    "# === Loop ekstraksi fitur audio ===\n",
    "for label in labels:\n",
    "    folder = os.path.join(DATA_DIR, label)\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"Folder {folder} tidak ditemukan, skip.\")\n",
    "        continue\n",
    "\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".m4a\") or file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(folder, file)\n",
    "\n",
    "            if file.endswith(\".m4a\"):\n",
    "                wav_path = file_path.replace(\".m4a\", \".wav\")\n",
    "                try:\n",
    "                    audio = AudioSegment.from_file(file_path, format=\"m4a\")\n",
    "                    audio.export(wav_path, format=\"wav\")\n",
    "                    file_path = wav_path\n",
    "                except Exception as e:\n",
    "                    print(f\"Gagal konversi {file_path}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "            if np.max(np.abs(y)) > 0:\n",
    "                y = y / np.max(np.abs(y))\n",
    "\n",
    "            feat_vector = []\n",
    "\n",
    "            # Fitur statistik dari sinyal mentah\n",
    "            feat_vector.extend(extract_stats(y))\n",
    "\n",
    "            # Fitur temporal\n",
    "            zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
    "            feat_vector.extend(extract_stats(zcr))\n",
    "            rms = librosa.feature.rms(y=y)[0]\n",
    "            feat_vector.extend(extract_stats(rms))\n",
    "\n",
    "            # Fitur spektral\n",
    "            centroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "            feat_vector.extend(extract_stats(centroid))\n",
    "            bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]\n",
    "            feat_vector.extend(extract_stats(bandwidth))\n",
    "            rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
    "            feat_vector.extend(extract_stats(rolloff))\n",
    "            flatness = librosa.feature.spectral_flatness(y=y)[0]\n",
    "            feat_vector.extend(extract_stats(flatness))\n",
    "            contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "            for band in contrast:\n",
    "                feat_vector.extend(extract_stats(band))\n",
    "            chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "            for bin_chroma in chroma:\n",
    "                feat_vector.extend(extract_stats(bin_chroma))\n",
    "\n",
    "            # MFCC (40 koefisien) + delta + delta-delta\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "            delta = librosa.feature.delta(mfcc)\n",
    "            delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "            for coeff in mfcc:\n",
    "                feat_vector.extend(extract_stats(coeff))\n",
    "            for coeff in delta:\n",
    "                feat_vector.extend(extract_stats(coeff))\n",
    "            for coeff in delta2:\n",
    "                feat_vector.extend(extract_stats(coeff))\n",
    "\n",
    "            # Tambahkan ke dataset dengan satu label gabungan\n",
    "            features.append(feat_vector)\n",
    "            full_labels.append(label)\n",
    "\n",
    "# === Buat DataFrame ===\n",
    "df = pd.DataFrame(features)\n",
    "df[\"label\"] = full_labels\n",
    "\n",
    "print(f\"Total data: {len(df)}\")\n",
    "print(f\"Jumlah fitur per file: {df.shape[1]-1}\")\n",
    "print(\"\\nDistribusi Label:\")\n",
    "print(df['label'].value_counts())\n",
    "print(\"\\nData Head:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ee9fdf",
   "metadata": {},
   "source": [
    "## **2. Preprocessing, Training & Validasi Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfff3e6",
   "metadata": {},
   "source": [
    "### **2.1 Seleksi Fitur, Reduksi Dimensi, dan Pelatihan Model**\n",
    "\n",
    "Proses ini menggabungkan beberapa langkah:\n",
    "1.  **Seleksi Fitur**: Menggunakan *Mutual Information* untuk memilih fitur-fitur yang paling informatif.\n",
    "2.  **Reduksi Dimensi**: Menggunakan PCA untuk mengurangi jumlah fitur dan menangkap variasi data yang paling penting.\n",
    "3.  **Pelatihan**: Melatih model *Ensemble Voting Classifier* yang terdiri dari SVM, RandomForest, dan GradientBoosting.\n",
    "4.  **Validasi**: Menggunakan *Stratified K-Fold Cross-Validation* untuk mendapatkan estimasi performa model yang lebih robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan fitur (X) dan target (y)\n",
    "X = df.drop(columns=[\"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "# --- 1. Seleksi Fitur dengan Mutual Information ---\n",
    "# Berdasarkan analisis sebelumnya, threshold IG 0.3 untuk target 'orang' \n",
    "# (yang lebih sulit) memberikan hasil baik, kita gunakan nilai ini sebagai awal.\n",
    "IG_THRESHOLD = 0.2  # Nilai ini bisa disesuaikan kembali\n",
    "\n",
    "mi_scores = mutual_info_classif(X, y)\n",
    "selected_features = X.columns[mi_scores > IG_THRESHOLD]\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "print(f\"Jumlah fitur setelah seleksi IG (threshold > {IG_THRESHOLD}): {X_selected.shape[1]}\")\n",
    "\n",
    "# --- 2. Reduksi Dimensi dengan PCA ---\n",
    "PCA_VARIANCE = 0.95 # Mempertahankan 95% varians\n",
    "pca = PCA(n_components=PCA_VARIANCE)\n",
    "X_pca = pca.fit_transform(X_selected)\n",
    "\n",
    "print(f\"Jumlah komponen PCA (variance > {PCA_VARIANCE}): {X_pca.shape[1]}\")\n",
    "\n",
    "# --- 3. Definisi Model Ensemble ---\n",
    "svm = SVC(kernel=\"rbf\", C=10, gamma=\"scale\", probability=True, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "gb = GradientBoostingClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[(\"svm\", svm), (\"rf\", rf), (\"gb\", gb)],\n",
    "    voting=\"soft\"\n",
    ")\n",
    "\n",
    "# --- 4. Cross-Validation ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(ensemble_model, X_pca, y, cv=cv, scoring=\"accuracy\")\n",
    "\n",
    "print(f\"\\nHasil Cross-Validation (5-fold):\")\n",
    "print(f\"Akurasi per fold: {cv_scores}\")\n",
    "print(f\"Rata-rata Akurasi CV: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"Standar Deviasi Akurasi CV: {np.std(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d82033",
   "metadata": {},
   "source": [
    "## **3. Evaluasi & Penyimpanan Model Final**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca33906",
   "metadata": {},
   "source": [
    "### **3.1 Latih & Evaluasi pada Data Test**\n",
    "\n",
    "Setelah divalidasi, model akhir dilatih pada seluruh data training dan dievaluasi performanya pada data test yang belum pernah dilihat sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af49a8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data menjadi training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Latih model final pada seluruh data training\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "# Evaluasi final\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Akurasi Model Final pada Data Test: {final_accuracy:.4f}\\n\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualisasi confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix Model Final\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0947811",
   "metadata": {},
   "source": [
    "### **3.2 Simpan Model dan Objek Preprocessing**\n",
    "\n",
    "Menyimpan model yang telah dilatih beserta semua komponen prapemrosesan (`pca`, `selected_features`) agar dapat digunakan kembali saat deployment untuk memproses data baru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb114e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latih ulang model dan PCA pada keseluruhan data untuk deployment\n",
    "print(\"Melatih ulang model pada keseluruhan data...\")\n",
    "final_pca = PCA(n_components=PCA_VARIANCE)\n",
    "final_X_pca = final_pca.fit_transform(X_selected) # X_selected dari sel sebelumnya\n",
    "\n",
    "final_model = VotingClassifier(\n",
    "    estimators=[(\"svm\", svm), (\"rf\", rf), (\"gb\", gb)],\n",
    "    voting=\"soft\"\n",
    ")\n",
    "final_model.fit(final_X_pca, y)\n",
    "\n",
    "# Simpan semua komponen yang diperlukan\n",
    "joblib.dump(final_model, \"model_klasifikasi_suara.pkl\")\n",
    "joblib.dump(final_pca, \"pca_transform.pkl\")\n",
    "joblib.dump(selected_features, \"selected_features_ig.pkl\")\n",
    "joblib.dump(list(X.columns), \"semua_fitur.pkl\") # Untuk referensi urutan fitur\n",
    "\n",
    "print(\"\\nModel dan objek preprocessing berhasil disimpan:\")\n",
    "print(\"- model_klasifikasi_suara.pkl\")\n",
    "print(\"- pca_transform.pkl\")\n",
    "print(\"- selected_features_ig.pkl\")\n",
    "print(\"- semua_fitur.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
